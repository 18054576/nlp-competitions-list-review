
### 背景

智能客服聊天机器人场景中，计算客户提出问题和知识库问题的相似度。在基于检索的问答系统中，第一步定位出最相似问题，再对问题给出答案。

### 数据

数据脱敏。原始文本信息编码为单字和单词序列，同时给出单字和单词的300维的词向量(基于Google的Word2Vec训练得到)。数据主要分为两块：第一是标注后的文本；第二是没有标注的文本；其中第一部分出现的文本一定在第二部分中。

### 评测指标

logloss。虽然是一个二分类问题，但是针对分类问题，除了常用的评测指标，例如精度和召回等，直接用损失函数作为评测指标也是常见的，印象中在天池的某个比赛中也是直接使用损失函数，在某些论文中也会看到类似评测方式。

### 预处理

#### (1)前言

既然是分类问题，自然要去可以考虑不平衡的问题，典型的方式标签传播等。此处可以参照[WSDM2019_真假新闻甄别](https://github.com/zhpmatrix/nlp-competitions-list-review/blob/master/WSDM_Cup_2019_%E7%9C%9F%E5%81%87%E6%96%B0%E9%97%BB%E7%94%84%E5%88%AB.md)。

#### (2)mixup

mixup是CVPR2018的一篇文章，一种数据增强的手段，简单有效。比如，一张狗的图片A和一张猫的图片B，mixup的结果可以是0.5A+0.5B后的一张新的图片，分类损失函数的构成也是0.5Loss(A)+0.5Loss(B)，那么映射到文本中，则是对文本Embedding后的文本表示进行操作。但是这样看似是合理的，由于文本是离散的，两个句子混合后可能语义层面就会发生较大的变化。因此，一种可能的方式是，假设A1,A2是相同极性的文本，B1,B2是相同极性的文本，则可以分别对A和B进行mixup，从理论上可以减少语义改变的风险。


### 模型选择

比赛方案多数整体上围绕Siamese RNN来进行，这个比赛进行的时候，BERT等系列工作还没有出现。模型架构如下：

![img](http://wx1.sinaimg.cn/mw690/aba7d18bgy1g17468af0kj20r40hwq83.jpg)

### 相关比赛

[Kaggle-Quora Question Pairs](https://www.kaggle.com/c/quora-question-pairs)，[ATEC-NLP之问题相似度计算](https://dc.cloud.alipay.com/index#/topic/intro?id=8)，[天池-CIKM2018-AnalytiCup](https://tianchi.aliyun.com/competition/entrance/231661/introduction)，部分比赛的复盘会在其他文章中给出。参考资料中同时给出了名次较好的同学的推荐的论文，更多的论文可以参照NLI领域的文章。

### 总结

问题相似度问题可以建模为一个句子对输入的问题，NLP中典型的任务场景是自然语言推理(NLI)。围绕该任务，相关工作已经非常多了，由于任务的简单性和模型的简洁性，Github相关的实现也非常多。适合拿该任务进行代码练习和建立对NLP任务的直觉。虽然这样讲，大概率情况下，这些工作应该比不过BERT。因为比赛的时候，BERT没有出现，所以方案中多数选择了一些传统的DL模型。


### 参考资料

1.[Applying Deep Learning to Answer Selection: A Study And An Open Task](https://arxiv.org/pdf/1508.01585.pdf)

2.[Learning Text Similarity with Siamese Recurrent Networks](http://www.aclweb.org/anthology/W16-1617)

3.[The Stanford Natural Language Inference Corpus](https://nlp.stanford.edu/projects/snli/)

4.《DR-BiLSTM: Dependent Reading Bidirectional LSTM for Natural Language Inference》

5.《Bilateral Multi-Perspective Matching for Natural Language Sentences》