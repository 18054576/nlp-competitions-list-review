### 前言

这个比赛和[天池平台\_瑞金医院MMC人工智能辅助构建知识图谱大赛](https://github.com/zhpmatrix/nlp-competitions-list-review/blob/master/%E5%A4%A9%E6%B1%A0%E5%B9%B3%E5%8F%B0_%E7%91%9E%E9%87%91%E5%8C%BB%E9%99%A2MMC%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E8%BE%85%E5%8A%A9%E6%9E%84%E5%BB%BA%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%A4%A7%E8%B5%9B.md)的解决思路类似。主要特色在于数据集，官方提到该数据集是业界规模最大的基于schema的中文信息抽取数据集，数据集中的句子来自百度百科和百度信息流文本。

### 数据分析

43万三元组数据，21万中文句子和50个已经定义好的schema。官方已经划分了训练集/验证集/测试集，统计如下表：

|训练集|验证集|测试集|
|------|------|------|
|17W|2W|2W|

### 赛前想法

正值比赛期间百度放出ERNIE的工作，训练数据相比BERT，由三类组成：百科类，新闻资讯类，对话类。而且BERT用于句子分类比赛，目前已经可以看到在多个比赛任务上取得优秀的成绩。因此，基于ERNIE或者BERT做FineTuning，依然是一个值得尝试的思路。